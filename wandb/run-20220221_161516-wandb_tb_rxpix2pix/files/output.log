create web directory ./checkpoints/teste_rxpix2pix/web...
learning rate 0.0002000 -> 0.0002000
/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
(epoch: 1, iters: 100, time: 0.073, data: 2.071) G_GAN: 1.001 G_L1: 12.667 D_real: 0.450 D_fake: 0.721
(epoch: 1, iters: 200, time: 0.083, data: 37.220) G_GAN: 0.801 G_L1: 19.359 D_real: 1.035 D_fake: 0.360
End of epoch 1 / 11 	 Time Taken: 83 sec
learning rate 0.0002000 -> 0.0002000
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
(epoch: 2, iters: 66, time: 0.065, data: 73.654) G_GAN: 1.102 G_L1: 12.605 D_real: 0.749 D_fake: 0.622
(epoch: 2, iters: 166, time: 1.194, data: 24.554) G_GAN: 1.099 G_L1: 13.247 D_real: 0.659 D_fake: 0.288
OrderedDict([('real_A', tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]],
         [[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]],
         [[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]]]], device='cuda:0')), ('fake_B', tensor([[[[-0.0354,  0.1411, -0.0151,  ...,  0.0565, -0.2236, -0.0791],
          [-0.2044,  0.0505,  0.3449,  ..., -0.1812,  0.3997, -0.1967],
          [ 0.1058, -0.3986,  0.2450,  ..., -0.3524, -0.0399,  0.0944],
          ...,
          [ 0.0549,  0.4397,  0.1756,  ...,  0.2474, -0.0312, -0.2166],
          [ 0.3361, -0.2916,  0.2345,  ...,  0.2156,  0.0592,  0.0532],
          [-0.0588,  0.0140, -0.0303,  ...,  0.1696, -0.0351,  0.0520]],
         [[ 0.0140,  0.0359,  0.0048,  ..., -0.1246,  0.1271, -0.0047],
          [ 0.0504,  0.2855,  0.0514,  ...,  0.4169,  0.1006,  0.4596],
          [-0.1186, -0.1769, -0.0653,  ..., -0.0319,  0.3485, -0.0055],
          ...,
          [ 0.1466,  0.4684,  0.1463,  ...,  0.5056,  0.3442,  0.0856],
          [-0.2328, -0.3795,  0.0350,  ..., -0.0209, -0.0647, -0.0130],
          [ 0.0959, -0.0249,  0.0924,  ..., -0.0033, -0.0203,  0.1487]],
         [[ 0.1036,  0.1760,  0.1767,  ...,  0.0706,  0.0517,  0.0336],
          [-0.2479,  0.1697, -0.5370,  ..., -0.0687, -0.3706,  0.0295],
          [ 0.0086,  0.3477,  0.2627,  ...,  0.1065,  0.5327, -0.0841],
          ...,
          [-0.2555, -0.0824, -0.3653,  ...,  0.0423, -0.2048, -0.0710],
          [ 0.2479, -0.0306,  0.0699,  ..., -0.1593,  0.3931, -0.0824],
          [-0.0007, -0.0180,  0.0086,  ...,  0.3316,  0.0579, -0.0209]]]],
       device='cuda:0')), ('real_B', tensor([[[[-0.9765, -0.9765, -0.9765,  ..., -0.9686, -0.9686, -0.9686],
          [-0.9765, -0.9765, -0.9843,  ..., -0.9608, -0.9608, -0.9608],
          [-0.9843, -0.9843, -0.9922,  ..., -0.9529, -0.9529, -0.9529],
          ...,
          [-0.9451, -0.9529, -0.9529,  ..., -0.6078, -0.9294, -0.9059],
          [-0.9529, -0.9529, -0.9608,  ..., -0.6784, -0.9294, -0.9059],
          [-0.9529, -0.9529, -0.9608,  ..., -0.7412, -0.9294, -0.9059]],
         [[-0.9765, -0.9765, -0.9765,  ..., -0.9686, -0.9686, -0.9686],
          [-0.9765, -0.9765, -0.9843,  ..., -0.9608, -0.9608, -0.9608],
          [-0.9843, -0.9843, -0.9922,  ..., -0.9529, -0.9529, -0.9529],
          ...,
          [-0.9451, -0.9529, -0.9529,  ..., -0.6078, -0.9294, -0.9059],
          [-0.9529, -0.9529, -0.9608,  ..., -0.6784, -0.9294, -0.9059],
          [-0.9529, -0.9529, -0.9608,  ..., -0.7412, -0.9294, -0.9059]],
         [[-0.9765, -0.9765, -0.9765,  ..., -0.9686, -0.9686, -0.9686],
          [-0.9765, -0.9765, -0.9843,  ..., -0.9608, -0.9608, -0.9608],
          [-0.9843, -0.9843, -0.9922,  ..., -0.9529, -0.9529, -0.9529],
          ...,
          [-0.9451, -0.9529, -0.9529,  ..., -0.6078, -0.9294, -0.9059],
          [-0.9529, -0.9529, -0.9608,  ..., -0.6784, -0.9294, -0.9059],
          [-0.9529, -0.9529, -0.9608,  ..., -0.7412, -0.9294, -0.9059]]]],
       device='cuda:0'))])
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
Traceback (most recent call last):
  File "train.py", line 126, in <module>
    val_kl_rr, val_js_rr = calculate_divergences(data_val, data_val)
  File "/content/gdrive/MyDrive/pix2pix/pix2pixTB/rxpix2pix/util/stats.py", line 58, in calculate_divergences
    for r_idx, f_idx in itertools.permutations(list(range(real_samples.shape[0])), 2):
AttributeError: 'dict' object has no attribute 'shape'