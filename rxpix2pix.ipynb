{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/pix2pix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IepncFlnvxtm","executionInfo":{"status":"ok","timestamp":1645640691580,"user_tz":180,"elapsed":20326,"user":{"displayName":"Otto Tavares","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17399973907655859682"}},"outputId":"dd0d96b3-1fbb-4bbe-afe7-817a2896b755"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"markdown","metadata":{"id":"7wNjDKdQy35h"},"source":["# Install"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRm-USlsHgEV"},"outputs":[],"source":["#!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Pt3igws3eiVp","executionInfo":{"status":"ok","timestamp":1645640695963,"user_tz":180,"elapsed":713,"user":{"displayName":"Otto Tavares","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17399973907655859682"}}},"outputs":[],"source":["import os\n","os.chdir('gdrive/MyDrive/pix2pix/pix2pixTB/rxpix2pix/')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1EySlOXwwoa","executionInfo":{"status":"ok","timestamp":1645640718439,"user_tz":180,"elapsed":20562,"user":{"displayName":"Otto Tavares","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17399973907655859682"}},"outputId":"0df70fe7-9b15-43c7-aa81-1d27cab4a928"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.10.0+cu111)\n","Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.11.1+cu111)\n","Collecting dominate>=2.4.0\n","  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n","Collecting visdom>=0.1.8.8\n","  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 676 kB 14.9 MB/s \n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.7 MB 39.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.10.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.21.5)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.23.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (22.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n","Collecting jsonpatch\n","  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n","Collecting torchfile\n","  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n","Collecting websocket-client\n","  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53 kB 2.3 MB/s \n","\u001b[?25hCollecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181 kB 49.5 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (5.4.8)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.6-py2.py3-none-any.whl (144 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 37.6 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.17.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.13)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb->-r requirements.txt (line 5)) (1.1.0)\n","Collecting jsonpointer>=1.9\n","  Downloading jsonpointer-2.2-py2.py3-none-any.whl (7.5 kB)\n","Building wheels for collected packages: visdom, pathtools, torchfile\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=b602e0040ed7cae1a155a4c30a8fe1f627ff6a92ca6416e7e2d5fb2a83a6f3d3\n","  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=eceeedb3e1c404816a4facabb6e83834b069848e9a0fcd6694d4de998513923d\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=71e41093801f2a2a648be82852b68c58a333a630774ebfd5776e60f87075b285\n","  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n","Successfully built visdom pathtools torchfile\n","Installing collected packages: smmap, jsonpointer, gitdb, yaspin, websocket-client, torchfile, shortuuid, sentry-sdk, pathtools, jsonpatch, GitPython, docker-pycreds, wandb, visdom, dominate\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 dominate-2.6.0 gitdb-4.0.9 jsonpatch-1.32 jsonpointer-2.2 pathtools-0.1.2 sentry-sdk-1.5.6 shortuuid-1.0.8 smmap-5.0.0 torchfile-0.1.0 visdom-0.1.8.9 wandb-0.12.10 websocket-client-1.2.3 yaspin-2.1.0\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","source":["!python train.py --dataroot /content/gdrive/MyDrive/pix2pix/data/unaligned --model pix2pix --dataset_mode skfold --direction AtoB --name teste_rxpix2pix --use_wandb --wandb_fold_id wandb_tb_rxpix2pix --gpu_ids 0 --val_freq 1 --num_val 50 --n_epochs 10 --n_epochs_decay 1 --test 5 --sort 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHj2cWTTv-9u","executionInfo":{"status":"ok","timestamp":1645647925742,"user_tz":180,"elapsed":156222,"user":{"displayName":"Otto Tavares","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17399973907655859682"}},"outputId":"8dde8d7d-d8e8-4140-a4a7-d1f45c697685"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------- Options ---------------\n","               batch_size: 1                             \n","                    beta1: 0.5                           \n","          checkpoints_dir: ./checkpoints                 \n","           continue_train: False                         \n","                crop_size: 256                           \n","                 dataroot: /content/gdrive/MyDrive/pix2pix/data/unaligned\t[default: None]\n","           dataset_action: False                         \n","             dataset_mode: skfold                        \t[default: aligned]\n","                direction: AtoB                          \n","              display_env: main                          \n","             display_freq: 400                           \n","               display_id: 1                             \n","            display_ncols: 4                             \n","             display_port: 8097                          \n","           display_server: http://localhost              \n","          display_winsize: 256                           \n","                    epoch: latest                        \n","              epoch_count: 1                             \n","                 gan_mode: vanilla                       \n","                  gpu_ids: 0                             \n","                init_gain: 0.02                          \n","                init_type: normal                        \n","                 input_nc: 3                             \n","                     isTB: True                          \n","                  isTrain: True                          \t[default: None]\n","          is_resume_wandb: False                         \n","                lambda_L1: 100.0                         \n","                load_iter: 0                             \t[default: 0]\n","                load_size: 286                           \n","                       lr: 0.0002                        \n","           lr_decay_iters: 50                            \n","                lr_policy: linear                        \n","         max_dataset_size: inf                           \n","                    model: pix2pix                       \t[default: cycle_gan]\n","                 n_epochs: 10                            \t[default: 100]\n","           n_epochs_decay: 1                             \t[default: 100]\n","               n_layers_D: 3                             \n","                     name: teste_rxpix2pix               \t[default: experiment_name]\n","                      ndf: 64                            \n","                     netD: basic                         \n","                     netG: unet_256                      \n","                      ngf: 64                            \n","               no_dropout: False                         \n","                  no_flip: False                         \n","                  no_html: False                         \n","                     norm: batch                         \n","              num_threads: 4                             \n","                  num_val: 50                            \t[default: 400]\n","                output_nc: 3                             \n","                    phase: train                         \n","                pool_size: 0                             \n","               preprocess: resize_and_crop               \n","               print_freq: 100                           \n","             save_by_iter: False                         \n","          save_epoch_freq: 5                             \n","         save_latest_freq: 5000                          \n","                     seed: 512                           \t[default: 512]\n","           serial_batches: False                         \n","                     sort: 5                             \t[default: 0]\n","                   suffix:                               \n","                     test: 5                             \t[default: 0]\n","            train_dataset: True                          \n","         update_html_freq: 1000                          \n","                use_wandb: True                          \t[default: False]\n","                 val_freq: 1                             \t[default: 400]\n","                  verbose: False                         \n","            wandb_fold_id: wandb_tb_rxpix2pix            \t[default: None]\n","----------------- End -------------------\n","['/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0327_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0328_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0329_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0330_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0331_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0332_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0334_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0335_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0337_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0339_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0340_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0361_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0362_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0363_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0364_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0367_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0368_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0369_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0371_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0372_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0373_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0374_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0375_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0376_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0377_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0378_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0379_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0380_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0381_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0382_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0383_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0385_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0386_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0388_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0389_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0390_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0391_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0392_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0393_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0394_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0395_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0396_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0397_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0398_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0400_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0402_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0404_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0405_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0408_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0409_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0410_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0411_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0412_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0413_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0414_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0415_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0416_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0417_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0418_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0421_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0423_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0426_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0427_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0428_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0429_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0430_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0431_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0432_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0434_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0438_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0439_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0442_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0443_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0444_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0446_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0448_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0449_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0450_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0451_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0452_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0454_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0456_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0457_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0459_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0460_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0462_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0463_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0464_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0465_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0466_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0468_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0469_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0472_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0473_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0474_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0475_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0476_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0477_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0478_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0479_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0480_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0501_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0504_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0507_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0508_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0510_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0511_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0512_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0513_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0514_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0517_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0518_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0519_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0521_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0522_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0523_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0524_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0525_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0526_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0527_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0528_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0529_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0530_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0531_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0532_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0533_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0534_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0535_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0536_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0537_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0538_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0540_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0542_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0543_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0544_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0545_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0546_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0547_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0548_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0549_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0550_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0551_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0552_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0553_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0554_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0555_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0556_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0557_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0558_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0559_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0566_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0568_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0569_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0570_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0573_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0574_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0575_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0576_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0577_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0578_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0579_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0580_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0581_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0582_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0583_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0584_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0585_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0586_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0587_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0588_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0589_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0590_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0591_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0593_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0594_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0595_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0596_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0599_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0600_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0602_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0603_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0604_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0605_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0606_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0607_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0608_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0609_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0610_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0611_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0612_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0613_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0614_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0615_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0616_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0617_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0618_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0619_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0622_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0623_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0624_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0625_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0626_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0627_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0628_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0629_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0630_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0631_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0632_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0633_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0636_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0637_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0638_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0639_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0640_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0641_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0642_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0643_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0644_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0645_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0646_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0648_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0649_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0650_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0651_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0652_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0653_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0654_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0655_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0656_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0658_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0659_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0660_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0662_1.png']\n","dataset [SkfoldDataset] was created\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","['/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0338_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0366_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0370_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0399_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0407_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0419_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0420_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0422_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0424_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0425_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0455_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0461_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0470_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0503_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0509_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0515_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0539_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0571_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0572_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0592_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0597_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0601_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0634_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0635_1.png', '/content/gdrive/MyDrive/pix2pix/data/unaligned/AB/CHNCXR_0661_1.png']\n","dataset [SkfoldDataset] was created\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","The number of training images = 233\n","The number of val images = 25\n","initialize network with normal\n","initialize network with normal\n","model [Pix2PixModel] was created\n","---------- Networks initialized -------------\n","[Network G] Total number of parameters : 54.414 M\n","[Network D] Total number of parameters : 2.769 M\n","-----------------------------------------------\n","Setting up a new session...\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33motavares\u001b[0m (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mteste_rxpix2pix\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/otavares/CycleGAN-and-pix2pix\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/otavares/CycleGAN-and-pix2pix/runs/wandb_tb_rxpix2pix\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/gdrive/MyDrive/pix2pix/pix2pixTB/rxpix2pix/wandb/run-20220223_202402-wandb_tb_rxpix2pix\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n","\n","create web directory ./checkpoints/teste_rxpix2pix/web...\n","learning rate 0.0002000 -> 0.0002000\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","OrderedDict([('G_GAN', 1.010938286781311), ('G_L1', 15.4627685546875), ('D_real', 1.0096080303192139), ('D_fake', 0.9326112270355225)])\n","(epoch: 1, iters: 100, time: 0.077, data: 3.469) G_GAN: 1.011 G_L1: 15.463 D_real: 1.010 D_fake: 0.933 \n","Error in sys.excepthook:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/exit_hooks.py\", line 43, in exc_handler\n","    def exc_handler(\n","KeyboardInterrupt\n","\n","Original exception was:\n","Traceback (most recent call last):\n","  File \"train.py\", line 63, in <module>\n","    for i, data in enumerate(dataset):  # inner loop within one epoch\n","  File \"/content/gdrive/MyDrive/pix2pix/pix2pixTB/rxpix2pix/data/__init__.py\", line 90, in __iter__\n","    for i, data in enumerate(self.dataloader):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1186, in _next_data\n","    idx, data = self._get_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1152, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 990, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n","    if not self._poll(timeout):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n","    return self._poll(timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n","    r = wait([self], timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 4629... (success).\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   D_fake â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:   D_real â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:    G_GAN â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:     G_L1 â–\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:   D_fake 0.93261\n","\u001b[34m\u001b[1mwandb\u001b[0m:   D_real 1.00961\n","\u001b[34m\u001b[1mwandb\u001b[0m:    G_GAN 1.01094\n","\u001b[34m\u001b[1mwandb\u001b[0m:     G_L1 15.46277\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mteste_rxpix2pix\u001b[0m: \u001b[34mhttps://wandb.ai/otavares/CycleGAN-and-pix2pix/runs/wandb_tb_rxpix2pix\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220223_202402-wandb_tb_rxpix2pix/logs/debug.log\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n"]}]},{"cell_type":"markdown","metadata":{"id":"8daqlgVhw29P"},"source":["# Datasets\n","\n","Download one of the official datasets with:\n","\n","-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n","\n","Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vrdOettJxaCc"},"outputs":[],"source":["!bash ./datasets/download_pix2pix_dataset.sh facades"]},{"cell_type":"markdown","metadata":{"id":"gdUz4116xhpm"},"source":["# Pretrained models\n","\n","Download one of the official pretrained models with:\n","\n","-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n","\n","Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GC2DEP4M0OsS"},"outputs":[],"source":["!bash ./scripts/download_pix2pix_model.sh facades_label2photo"]},{"cell_type":"markdown","metadata":{"id":"yFw1kDQBx3LN"},"source":["# Training\n","\n","-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n","\n","Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sp7TCT2x9dB"},"outputs":[],"source":["!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA --use_wandb"]},{"cell_type":"markdown","metadata":{"id":"9UkcaFZiyASl"},"source":["# Testing\n","\n","-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n","\n","Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n","\n","> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n","> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n","\n","> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n","\n","> See a list of currently available models at ./scripts/download_pix2pix_model.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mey7o6j-0368"},"outputs":[],"source":["!ls checkpoints/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCsKkEq0yGh0"},"outputs":[],"source":["!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_label2photo_pretrained --use_wandb"]},{"cell_type":"markdown","metadata":{"id":"OzSKIPUByfiN"},"source":["# Visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Mgg8raPyizq"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n","plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0G3oVH9DyqLQ"},"outputs":[],"source":["img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n","plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErK5OC1j1LH4"},"outputs":[],"source":["img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n","plt.imshow(img)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"rxpix2pix.ipynb","provenance":[]},"environment":{"name":"tf2-gpu.2-3.m74","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}